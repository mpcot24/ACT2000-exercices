\section*{Chapitre \ref{chap:tests}}
\addcontentsline{toc}{section}{Chapitre \protect\ref{chap:tests}}

\begin{solution}{6.1}
\begin{enumerate}
\item L'hypothèse nulle est simple étant donné que $\Theta_0 = \{ 0,2\}$ ne contient qu'une seule valeur. La contre-hypothèse est composite étant donné que $\Theta_1 = [0,\, 0,2) \cup (0,2,\, 1]$ contient plus d'une valeur de $\theta$.

\item Les mesures $X_1, \ldots , X_{20}$ sont des variables aléatoires Bernoulli mutuellement indépendantes. La région critique est donc donnée par
$$
\mathcal{C} = \left\{ (x_1,\dots, x_{20}) \in \{0,1\}^n  :  x_1 + \dots + x_n \in \{ 0,1\} \cup \{7,\dots,20 \}\right \}.
$$

\item Parce que l'hypothèse nulle est simple, la taille du test et la probabilité d'erreur de type I sont les mêmes.
$$
\alpha =\Pr(X  \le 1, X \ge 7  |  p = 0,2).
$$
Sous l'hypothèse nulle, $X = X_1 + \cdots + X_{20}$ est une distribution binomiale de taille $n=20$ et probabilité $p=0,2$. Ainsi, $\alpha$ peut être calculé comme suit:
\begin{align*}
\Pr(X  \le 1, X \ge 7) &= 1 - \Pr(2 \le X \ge 6) \\
&= 1 - \sum_{x=2}^6 \Pr(X=x) \\
&= 1 - 0,8441322 \\
&= 0,1558678
\end{align*}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{pbinom}\hlstd{(}\hlnum{1}\hlstd{,}\hlkwc{size}\hlstd{=}\hlnum{20}\hlstd{,}\hlkwc{prob}\hlstd{=}\hlnum{0.2}\hlstd{)} \hlopt{+} \hlnum{1}\hlopt{-}\hlkwd{pbinom}\hlstd{(}\hlnum{6}\hlstd{,}\hlkwc{size}\hlstd{=}\hlnum{20}\hlstd{,}\hlkwc{prob}\hlstd{=}\hlnum{0.2}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] 0.1558678
\end{verbatim}
\end{kframe}
\end{knitrout}

\item La fonction de puissance à $p_1\in [0,1]$ arbitraire est donnée par
$$
\Pi(p_1) = \Pr(X  \le 1, X \ge 7  |  p =p_1)
$$
et peut être calculée par le fait que $X \sim Bin(n=20, p=p_1)$. On répète la même démarche qu'en (c) en changeant la probabilité $p$ de la loi Binomiale pour chacune des valeurs de $p_1$. Avec \textsf{R}, on trouve
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{p} \hlkwb{<-} \hlkwd{seq}\hlstd{(}\hlkwc{from}\hlstd{=}\hlnum{0}\hlstd{,}\hlkwc{to}\hlstd{=}\hlnum{1}\hlstd{,}\hlkwc{by}\hlstd{=}\hlnum{0.1}\hlstd{)}
\hlstd{power} \hlkwb{<-} \hlkwd{pbinom}\hlstd{(}\hlnum{1}\hlstd{,}\hlkwc{size}\hlstd{=}\hlnum{20}\hlstd{,}\hlkwc{prob}\hlstd{=p)} \hlopt{+} \hlnum{1}\hlopt{-}\hlkwd{pbinom}\hlstd{(}\hlnum{6}\hlstd{,}\hlkwc{size}\hlstd{=}\hlnum{20}\hlstd{,}\hlkwc{prob}\hlstd{=p)}
\hlstd{power}
\end{alltt}
\begin{verbatim}
##  [1] 1.0000000 0.3941331 0.1558678 0.3996274 0.7505134
##  [6] 0.9423609 0.9935345 0.9997390 0.9999982 1.0000000
## [11] 1.0000000
\end{verbatim}
\end{kframe}
\end{knitrout}
La courbe de la fonction de puissance peut être tracée avec les points $(\Pi(p_1), p_1)$. En \textsf{R}, elle peut être tracée comme suit:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{plot}\hlstd{(p,power,}\hlkwc{type}\hlstd{=}\hlstr{"b"}\hlstd{)}
\hlkwd{points}\hlstd{(p,power,}\hlkwc{pch}\hlstd{=}\hlnum{16}\hlstd{)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-32-1}

\end{knitrout}
La puissance à $p=0,2$ est égale à la probabilité d'erreur de type I $\alpha$, alors que pour $ p \ne 0,2$, la probabilité d'erreur de type II $\beta$ est donnée par $1 - \Pi(p)$.

\item La seule différence avec (d) est que maintenant $Y$ est une distribution binomiale de taille $n \in \{50,100\}$. La fonction de puissance à $$
p\in\{0,\,\, 0,1,\,\, 0,2,\,\, 0,3,\,\, 0,4,\,\, 0,5,\,\, 0,6,\,\, 0,7,\,\, 0,8,\,\, 0,9,\,\, 1\}
$$
pour $n=50$ et $n=100$ est calculée de la même façon qu'en (d) en changeant la taille $n$ de la loi Binomiale pour $50$ et $100$. En \textsf{R}, on trouve:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{(power.50} \hlkwb{<-} \hlkwd{pbinom}\hlstd{(}\hlnum{1}\hlstd{,}\hlkwc{size}\hlstd{=}\hlnum{50}\hlstd{,}\hlkwc{prob}\hlstd{=p)} \hlopt{+} \hlnum{1}\hlopt{-}\hlkwd{pbinom}\hlstd{(}\hlnum{6}\hlstd{,}\hlkwc{size}\hlstd{=}\hlnum{50}\hlstd{,}\hlkwc{prob}\hlstd{=p))}
\end{alltt}
\begin{verbatim}
##  [1] 1.0000000 0.2635590 0.8967945 0.9975067 0.9999860
##  [6] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
## [11] 1.0000000
\end{verbatim}
\begin{alltt}
\hlstd{(power.100} \hlkwb{<-} \hlkwd{pbinom}\hlstd{(}\hlnum{1}\hlstd{,}\hlkwc{size}\hlstd{=}\hlnum{100}\hlstd{,}\hlkwc{prob}\hlstd{=p)} \hlopt{+} \hlnum{1}\hlopt{-}\hlkwd{pbinom}\hlstd{(}\hlnum{6}\hlstd{,}\hlkwc{size}\hlstd{=}\hlnum{100}\hlstd{,}\hlkwc{prob}\hlstd{=p))}
\end{alltt}
\begin{verbatim}
##  [1] 1.0000000 0.8831661 0.9999220 1.0000000 1.0000000
##  [6] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
## [11] 1.0000000
\end{verbatim}
\end{kframe}
\end{knitrout}
De la même façon qu'en (d), le graphique ci-dessous trace les fonctions de puissance pour $n=5$ (en rouge) et $n=100$ (en bleu), avec la puissance pour $n=20$ (en noir).
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{plot}\hlstd{(p,power,}\hlkwc{type}\hlstd{=}\hlstr{"b"}\hlstd{)}
\hlkwd{points}\hlstd{(p,power.50,}\hlkwc{type}\hlstd{=}\hlstr{"b"}\hlstd{,}\hlkwc{col}\hlstd{=}\hlstr{"red"}\hlstd{)}
\hlkwd{points}\hlstd{(p,power.100,}\hlkwc{type}\hlstd{=}\hlstr{"b"}\hlstd{,}\hlkwc{col}\hlstd{=}\hlstr{"blue"}\hlstd{)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-34-1}

\end{knitrout}
Bien que la puissance se comporte bien si $p \ne 0,2$ (i.e., elle s'approche de 1), l'erreur de type I est complètement inacceptable: elle est aussi grande que $0,999$ quand $n=100$. Le test n'est pas du tout utile pour ces tailles d'échantillon.

\item La région de rejet devra dépendre de $n$, puisque plus la taille d'échantillon augmente, plus d'objets défectueux seront présents sous $\mathcal{H}_0$, simplement car plus d'objets sont inspectés. Sous l'hypothèse nulle, le nombre total d'objets défectueux va être une distribution binomiale de taille $n$ avec probabilité $p=0,2$. Les valeurs critiques pourraient être choisies comme des quantiles de la distribution binomiale.
\end{enumerate}
\end{solution}
\begin{solution}{6.2}
    \begin{enumerate}
    \item On a
      \begin{align*}
        f(x_1, \dots, x_n;\theta) &= \prod_{i=1}^n f(x_i;\theta) \\
        &= \theta^n\prod_{i=1}^nx_i^{\theta-1} \\
        &= \left(
          \theta^n \prod_{i=1}^n x_i^\theta
        \right)
        \left(
          \prod_{i=1}^n x_i^{-1}
        \right) \\
        &= g(t(x_1, \dots, x_n); \theta) h(x_1, \dots, x_n),
      \end{align*}
      où
      \begin{align*}
        g(y; \theta) &= \theta^n y^n \\
        t(x_1, \dots, x_n) &= \prod_{i=1}^n x_i \\
        h(x_1, \dots, x_n) &= \prod_{i=1}^n x_i^{-1}.
      \end{align*}
      Ainsi, par le théorème de factorisation de Fisher--Neyman, $T(X_1, \dots, X_n) = \prod_{i = 1}^n X_i$ est une
      statistique exhaustive pour $\theta$.
    \item D'une part, l'erreur de type I consiste à rejeter
      l'hypothèse $ \mathcal{H}_0$ alors qu'elle est vraie. La probabilité de
      faire ce type d'erreur, notée $\alpha$, correspond donc à la probabilité que
      la statistique du test se retrouve dans la région critique
      lorsque l'hypothèse $ \mathcal{H}_0$ est vraie. On a donc
      \begin{align*}
        \alpha &= \Prob{X_1X_2 \geq \frac{3}{4}; \theta = 1} \\
        &= \iint_C f_{X_1 X_2}(x_1, x_2; 1)\, dx_2 dx_1,
      \end{align*}
      où $C = \{(x_1, x_2); x_1 x_2 \geq 3/4\}$. Or,
      $$
      f_{X_1 X_2}(x_1,
      x_2; \theta) = f_{X_1}(x_1; \theta) f_{X_2}(x_2; \theta) =
      \theta^2 x_1^{\theta - 1} x_2^{\theta - 1},
      $$
      d'où $f_{X_1
        X_2}(x_1, x_2; 1) = 1$, $0 < x_1, x_2 < 1$. La région critique
      $C$ est représentée à la figure~\ref{fig:tests:x1x2}.
      \begin{figure}
        \centering
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}
\includegraphics[width=0.6\textwidth]{figure/unnamed-chunk-35-1}

\end{knitrout}
        \caption{Domaine de définition de la densité conjointe des
          variables $X_1$ et $X_2$ de
          l'exercice~\ref{chap:tests}.\ref{ex:tests:x1x2}. La zone
          hachurée est la région critique $C = \{(x, y); x y \geq
          3/4\}$ du test d'hypothèse.}
        \label{fig:tests:x1x2}
      \end{figure}
      Ainsi,
      \begin{align*}
        \alpha
        &= \int_{3/4}^1 \int_{3/(4 x_1)}^1 \,dx_2\,dx_1 \\
        &= \int_{3/4}^1
        \left(
          1 - \frac{3}{4x_1}
        \right)\, dx_1 \\
        &= \frac{1}{4} + \frac{3}{4} \ln \frac{3}{4} \\
        &\approx 0,034.
      \end{align*}

      D'autre part, l'erreur de type II consiste à ne pas rejeter
      l'hypothèse $ \mathcal{H}_0$ alors qu'elle est fausse. La valeur $\beta$
      est donc la probabilité que la statistique se retrouve à
      l'extérieur de la région critique lorsque l'hypothèse $ \mathcal{H}_0$ est
      fausse, c'est-à-dire
      \begin{align*}
        \beta &= \Prob{X_1 X_2 < \frac{3}{4}; \theta = 2} \\
        &= 1 - \Prob{X_1 X_2 \geq \frac{3}{4}; \theta = 2}\\
        &= 1 - \iint_C f_{X_1 X_2}(x_1, x_2; 2)\, dx_2 dx_1.
      \end{align*}
      Dès lors, puisque $f_{X_1 X_2}(x_1, x_2; 2) = 4 x_1 x_2$,
      \begin{align*}
        \beta
        &= 1 - \int_{3/4}^1 \int_{3/(4x_1)}^1 4 x_1 x_2\, dx_2\, dx_1\\
        &= \frac{9}{16} - \frac{9}{8}\ln \frac{3}{4} \\
        &\approx 0,886.
      \end{align*}
    \end{enumerate}
  
\end{solution}
\begin{solution}{6.3}
\begin{enumerate}
\item Ici, la fonction de distribution de l'échantillon est donnée par
$$
f(\boldsymbol{x}; \lambda) = e^{-\lambda n} \frac{\lambda^{x_1 + \dots + x_n}}{x_1! \times \dots \times x_n!}
$$
et le rapport de vraisemblance est
$$
\frac{f(\boldsymbol{x}; \lambda_1)}{f(\boldsymbol{x}; \lambda_0)} = e^{-\lambda_1 n + \lambda_0 n} \left(\frac{\lambda_1}{\lambda_0}\right)^{x_1 + \dots + x_n} = \exp\left\{ -(\lambda_1 - \lambda_0)n + n \bar x_n \ln\left(\frac{\lambda_1}{\lambda_0}\right) \right\}.
$$
Parce que les hypothèses sont simples, le Lemme de Neyman--Pearson dit que le test optimal rejette l'hypothèse nulle si pour une valeur critique $k>0$,
$$
\frac{f(\boldsymbol{x}; \lambda_1)}{f(\boldsymbol{x}; \lambda_0)} > \frac{1}{k}
$$
ce qui est équivalent à
$$
\exp\left\{ -(\lambda_1 - \lambda_0)n + n \bar x_n \ln\left(\frac{\lambda_1}{\lambda_0}\right) \right\} > \frac{1}{k}.
$$
Prendre le logarithme des deux côtés de l'inégalité donne
$$
\bar x_n > \underbrace{\frac{-\ln(k)/n + (\lambda_1 -\lambda_0)}{\ln(\lambda_1) - \ln(\lambda_0)}}_{=c}.
$$
Sous l'hypothèse nulle, on note que $n\bar X_n = X_1 + \dots + X_n$ est une distribution Poisson avec moyenne $n\lambda_0$. Ainsi, la valeur $c$ devrait être choisie telle que
$$
\Pr( n \bar X_n > nc  |  \lambda = \lambda_0) = \alpha
$$
pour un seuil $\alpha$, c'est-à-dire que $nc$ est le quantile $1-\alpha$ de la distribution Poisson avec moyenne $n\lambda_0$. À noter que le seuil de signification ne sera peut-être pas exact étant donné que la distribution Poisson est discrète.

\item Ici, le test optimal rejette l'hypothèse nulle si
$$
\frac{f(\boldsymbol{x}; \lambda_1)}{f(\boldsymbol{x}; \lambda_0)} = \exp\left\{ -(\lambda_1 - \lambda_0)n + n \bar x_n \ln\left(\frac{\lambda_1}{\lambda_0}\right) \right\} > 1,
$$
c'est-à-dire lorsque
$$
\bar x_n > \underbrace{\frac{\lambda_1 -\lambda_0}{\ln(\lambda_1) - \ln(\lambda_0)}}_{=c^*}.
$$

\item Si $n=20$ et $\lambda_0 = 1/20$, $n\bar X_n$ est une loi de Poisson avec moyenne $1$ sous l'hypothèse nulle. Le quantile de niveau $1-0,08 = 0,92$ de cette distribution est $2$ puisque
\begin{center}
\begin{tabular}{lcc}
$x$ & $\Pr(n\bar X_n =x)$ & $\Pr(n\bar X_n \leq x)$ \\
$0$ & $0,368$ & $0,368$ \\
$1$ & $0,368$ & $0,736$ \\
$2$ & $0,184$ & $0,920$ \\
\end{tabular}
\end{center}
%<<>>=
%qpois(0.932,lambda=5)
%@
Parce que
\begin{align*}
\Pr( n \bar X_n > nc  |  \lambda = \lambda_0) &= \alpha \\
1-\Pr( n \bar X_n \leq nc  |  \lambda = \lambda_0) &= \alpha
\end{align*}
%<<>>=
%round(1- ppois(8,lambda=5),3)
%@
la valeur critique $c$ égale  $2/20 = 0,1$ et le test rejette $\mathcal{H}_0$ si $n \bar X_n > 2$. La probabilité d'erreur de type I est donc
$$
\Pr(n\bar X_n > 2  |  \lambda = 1/20) = 0,08.
$$
La probabilité d'erreur de type II est donnée par
$$
\Pr(n \bar X_n \le 2  |  \lambda =1/10) = 0,6766764
$$
et peut être calculée par le fait que quand $\lambda =1/10$, $n\bar X_n$ est une loi de Poisson avec moyenne $2$.

%<<>>=
%round(ppois(8,lambda=10),3)
%@

\item Ici, la valeur de $c^\star$ est donnée par
$$
\frac{\lambda_1 -\lambda_0}{\ln(\lambda_1) - \ln(\lambda_0)} = \frac{1/20}{\ln(1/10) - \ln(1/20)} = 0.07213,
$$
donc le test rejette l'hypothèse nulle si
$$
n\bar X_n > nc^* = 20\times 0.07213 = 1.4427,
$$
i.e. si $n \bar X_n > 1$. La probabilité d'erreur de type I est
$$
\Pr(n \bar X_n > 1  |  \lambda =1/20) = 0.264.
$$
La probabilité d'erreur de type II est
$$
\Pr(n \bar X_n \le 1  |  \lambda =1/10) = 0.406,
$$
et la valeur minimale que peut atteindre $\alpha(\delta) + \beta(\delta)$ est
$$
\alpha(\delta) + \beta(\delta) = 0.264 + 0.406 = 0.67.
$$
\end{enumerate}
\end{solution}
\begin{solution}{6.4}
    On sait que $\bar{X} \sim \mathcal{N}(\mu, 5000^2/n)$. Or,
    \begin{align*}
      \alpha &= \prob{\bar{X} \geq c; \mu = \nombre{30 000}} \\
      &= 1 -
      \Phi\left(
        \frac{\sqrt{n}(c - \nombre{30000})}{\nombre{5000}}
      \right) \\
      \intertext{d'où}
      z_\alpha &=
      \frac{\sqrt{n}(c-\nombre{30000})}{\nombre{5000}}.
    \end{align*}
    De même,
    \begin{align*}
      \beta &= \prob{\bar{X} < c; \mu = \nombre{35000}}\\
      &= \Phi\left(
        \frac{\sqrt{n}(c - \nombre{35000})}{\nombre{5000}}
      \right), \\
      \intertext{d'où}
      z_{1 - \beta} &=
      \frac{\sqrt{n}(c-\nombre{35000})}{\nombre{5000}}.
    \end{align*}
    On trouve dans une table de la loi normale que $z_\alpha =
    z_{0,01} = 2,326$ et que $z_{1 - \beta} = z_{0,98} = -2,05$. En
    résolvant pour $n$ et $c$ le système à deux équations et deux
    inconnues, on obtient $n = 19,15$ et $c = \nombre{32658}$. Aux
    fins du test, on choisira donc une taille d'échantillon de $n =
    19$ ou $n = 20$.
  
\end{solution}
\begin{solution}{6.5}
   \begin{enumerate}
   \item Il s'agit d'un simple test sur une moyenne. La statistique
      pour un petit échantillon est
      \begin{align*}
        T &= \frac{\bar{X} - \mu_X}{\sqrt{S^2/n}} = \frac{\bar{X} - \nombre{3315}}{\sqrt{S^2/11}} \sim t_{10}.
      \end{align*}
      On rejette $ \mathcal{H}_0$ si $t > t_{10, \,0,01} = 2,764$.
   \item On commence par calculer les statistiques $\bar{X}$ et $S_X^2$,
   $$
   \bar{X} = 3385,91 \quad \mbox{ et } \quad S_X^2 = \nombre{113108,49}.
   $$
   On trouve que $t = 0,699 < t_{10, \,0,01} = 2,764$, on ne rejette donc pas $ \mathcal{H}_0$ à un seuil de signification de $1$~\%.
 %\item Le niveau de confiance auquel on rejetterait $ \mathcal{H}_0$ est $1 - p = format(1 - tx$p.value, dig = 4, dec = ",")$. %$

    \item On a un test unilatéral à gauche sur une variance pour lequel la statistique est
      \begin{align*}
        Y = \frac{(n-1) S^2}{\sigma^2} = \frac{(10) S^2}{525^2} \sim \chi^2_{10}.
      \end{align*}
      On rejette $ \mathcal{H}_0$ si $y < \chi_{10, \, 0,95}^2 = 3,94$.
    \item Ici, $y = 4,104 > 3,94$. On ne rejette donc pas $ \mathcal{H}_0$.
%   \item On a $p = \prob{Y < 4,103}$, où $Y \sim \chi^2(10)$. Or,
%<<echo=TRUE>>=
%pchisq(4.103, 10)
%@
%d'où le seuil observé du test sur la variance est %
%   $format(pchisq(4.103, 10), dig = 3, dec = ",")$.
    \end{enumerate}
  
\end{solution}
\begin{solution}{6.6}
   \begin{enumerate}
    \item La statistique à utiliser est la même qu'à l'exercice~\ref{chap:tests}.\ref{ex:tests:filles}.
    \item On commence par calculer les statistiques $\bar{Y}$ et $S_Y^2$,
   $$
   \bar{Y} = 3729,36 \quad \mbox{ et } \quad S_Y^2 = \nombre{116388,85}.
   $$
   On trouve que $t = 4,028 > t_{10, \,0,01} = 2,764$, on rejette donc $ \mathcal{H}_0$ à un seuil de signification de $1$~\%.
    \item La statistique à utiliser est la même qu'à l'exercice~\ref{chap:tests}.\ref{ex:tests:filles}.
    \item On a $y = 4,223 > 3,94$. On ne rejette donc pas $ \mathcal{H}_0$.
    \item Les moyennes semblent être différentes entre les deux groupes, mais les variances égales. On commence par vérifier si le ratio des variances est près de $1$. On teste
       \begin{align*}
         \mathcal{H}_0 &: \sigma_X^2 / \sigma_Y^2 = 1 \\
         \mathcal{H}_1 &: \sigma_X^2 / \sigma_Y^2 \ne 1
      \end{align*}
      La statistique à utiliser pour ce test est
      \begin{align*}
      F = \frac{S_Y^2 / \sigma_Y^2}{S_X^2 / \sigma_X^2} \sim \mathcal{F}_{m-1, n-1}
      \end{align*}
      Avec les données des deux numéros, on trouve que $f = 0,97$. À un seuil de signification de $\alpha = 10$\%, on trouve $\mathcal{F}_{10, 10, \, 0,05} = 2,98$ et $\mathcal{F}_{10, 10, \, 0,95} = 0,34$. On ne rejette donc pas $\mathcal{H}_0$ au seuil de $10$\%. Ainsi, on peut tester
      \begin{align*}
         \mathcal{H}_0 &: \mu_X = \mu_Y \\
         \mathcal{H}_1 &: \mu_X \ne \mu_Y
      \end{align*}
en supposant les variances égales. La statistique utilisée pour ce test est
\begin{align*}
W = \frac{(\bar{X} - \bar{Y}) - (\mu_X - \mu_Y)}{\sqrt{S_X^2/n+S_Y^2/m}} \sim t_{n+m-2}.
\end{align*}

Avec les données des deux numéros, on trouve que $w = -2,378$. À un seuil de signification de $\alpha = 5$\%, on trouve $t_{20, \, 0,025} = -2,086$ et $t_{20, \, 0,975} = 2,086$. On rejette donc $\mathcal{H}_0$ au seuil de $5$\%. On établit donc que les fillettes et les garçons nés au Québec ont un poids moyen différent les uns des autres.
    \end{enumerate}
  
\end{solution}
\begin{solution}{6.7}
    \begin{enumerate}
    \item Nous avons un test unilatéral à gauche sur la différence entre deux moyennes. En supposant égales les variances des deux populations, on a $X \sim \mathcal{N}(\mu_X, \sigma^2)$ et $Y \sim  \mathcal{N}(\mu_Y, \sigma^2)$. On sait que $\bar{X} \sim \mathcal{N}(\mu_X, \sigma^2/n)$ et $\bar{Y} \sim \mathcal{N}(\mu_Y, \sigma^2/m)$, d'où un estimateur de $\mu_X - \mu_Y$ sur lequel baser un test est
      \begin{equation*}
        \bar{X} - \bar{Y} \sim
        \mathcal{N}\left(
          \mu_X - \mu_Y, \frac{\sigma^2}{n} + \frac{\sigma^2}{m} \right).
      \end{equation*}
      La variance $\sigma^2$ est toutefois inconnue. Un estimateur de ce paramètre est l'estimateur combiné, soit la moyenne pondérée des estimateurs de chaque échantillon:
      \begin{equation*}
      S_p^2 = \frac{(n - 1) S_X^2 + (m - 1) S_Y^2}{n + m - 2}.
      \end{equation*}
      Or, $(n + m - 2) S_p^2/\sigma^2 \sim \chi^2(n + m - 2)$. Par conséquent,
   \begin{align*}
          T &= \frac{\D \frac{(\bar{X} - \bar{Y}) - (\mu_X-\mu_Y)}{%
            \sigma \sqrt{n^{-1} + m^{-1}}}}{%
          \D \sqrt{\frac{(n + m - 2) S_p^2}{\sigma^2}}} \\[6pt]
        &= \frac{(\bar{X} - \bar{Y}) - (\mu_X-\mu_Y)}{%
          \D\sqrt{\frac{(n-1) S_X^2 + (m-1) S_Y^2}{n + m - 2}
            \left(
              \frac{1}{n} + \frac{1}{m}
            \right)}} \sim t(m + n - 2).
      \end{align*}
On rejette $ \mathcal{H}_0: \mu_X \ge \mu_Y$ en faveur de $ \mathcal{H}_1: \mu_X < \mu_y$ si $t \leq -t_{0,05}(n + m - 2)$.
  \item Avec les données de l'énoncé, la valeur de la statistique développée en a) est $t = -0,838$, alors que le 95{\ieme} centile d'une loi $t$ avec $13 + 16 - 2 = 27$ degrés de liberté est $t_{0,05}(27) = 1,703$. Puisque $\abs{t} < 1,703$, on ne rejette pas $ \mathcal{H}_0$.

\item On a $p = \prob{T < -0,838}$, où $T \sim t(27)$. À l'aide de \textsf{R}, on trouve
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{pt}\hlstd{(}\hlopt{-}\hlnum{0.838}\hlstd{,} \hlkwc{df} \hlstd{=} \hlnum{27}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] 0.204694
\end{verbatim}
\end{kframe}
\end{knitrout}
      Puisque
      $p = 0,2047 > 0,05$, on ne rejette pas $ \mathcal{H}_0$. La conclusion est évidemment la même qu'en a).

 \item On souhaite tester l'égalité de deux variances, c'est-à-dire $ \mathcal{H}_0: \sigma_X^2 = \sigma_Y^2$ versus $ \mathcal{H}_1: \sigma_X^2 \ne \sigma_Y^2$. Pour ce faire, on se base sur le fait que
 $(n-1) S_X^2/\sigma_X^2 \sim \chi^2(n - 1)$ et que $(m-1) S_Y^2/\sigma_Y^2 \sim \chi^2(m - 1)$. Ainsi, sous $ \mathcal{H}_0$ (c'est-à-dire lorsque  $\sigma_X^2 = \sigma_Y^2$),
      \begin{displaymath}
        F = \frac{(n-1) S_X^2/(n - 1)}{(m-1) S_Y^2/(m - 1)} \sim F(n - 1, m - 1).
      \end{displaymath}
      On rejette $ \mathcal{H}_0$ si la valeur de la statistique est supérieure
      au $100(1 - \alpha/2)${\ieme} centile d'une loi $F$ avec $n - 1$
      et $m - 1$ degrés de liberté. Ici, on a $f = 0,8311$ et
      $f_{0,05}(12, 15) = 2,48$, et pour l'autre côté, la valeur de $f_{0,95}(12, 15)$ (ou de $f_{0,05}(15, 12)$) n'est pas donnée dans la table, mais on peut la trouver avec \textsf{R} comme suit:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{qf}\hlstd{(}\hlnum{0.05}\hlstd{,}\hlnum{12}\hlstd{,}\hlnum{15}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] 0.3821387
\end{verbatim}
\end{kframe}
\end{knitrout}
     Puisque $0.38 < 0,8311 < 2,48$,  on ne rejette donc pas $ \mathcal{H}_0$.
    L'hypothèse des variances égales est donc raisonnable.
    \end{enumerate}
  
\end{solution}
\begin{solution}{6.8}
    \begin{enumerate}
    \item Soit $X$ la variable aléatoire du nombre de dentistes qui
      recommande le dentifrice parmi un groupe-test de 390 dentistes.
      On a donc que $X \sim \text{Binomiale}(390, \theta)$ et on teste
      \begin{align*}
         \mathcal{H}_0 &: \theta = 0,75 \\
         \mathcal{H}_1 &: \theta \ne 0,75.
      \end{align*}
      Il s'agit d'un test bilatéral sur une proportion avec un grand
      échantillon. La statistique du test est
      \begin{displaymath}
        Z = \frac{\hat{\theta} - 0,75}{%
          \sqrt{0,75 (1 - 0,75)/390}}
      \end{displaymath}
      et on rejette $ \mathcal{H}_0$ si $\abs{z} > z_{\alpha/2}$. Ici, on a
      $\alpha = 0,05$, $\hat{\theta} = 273/390$, d'où $z = -2,28$.
      Puisque $\abs{z} > z_{0,025} = 1,96$, on juge, à un seuil de
      signification de 5~\%, que la proportion de dentistes qui
      recommandent le dentifrice est suffisamment éloignée de la
      prétention du fabricant pour rejetter l'hypothèse $ \mathcal{H}_0$.

%      On peut vérifier les résultats ci-dessus avec la fonction
%      \texttt{prop.test} de \textsf{R}:
%<<echo=TRUE>>=
%prop.test(273, n = 390, p = 0.75, correct = FALSE)
%@
%      On constate que la valeur test $\theta = 0,75$ ne se trouve pas
%      dans l'intervalle de confiance à 95~\%, d'où le rejet de
%      l'hypothèse $ \mathcal{H}_0$.
    \item Puisque $z_{0,005} = 2,576 > 2,28$, on ne rejette pas
      l'hypothèse  $ \mathcal{H}_0$ à un seuil de signification de 1~\%.
%      D'ailleurs un intervalle de confiance à 99~\% nous est fourni
%      par la fonction \texttt{prop.test}:
%<<echo=TRUE>>=
%prop.test(273, n = 390, p = 0.75, conf.level = 0.99,
%          correct = FALSE)
%@
%      On constate que cet intervalle comprend la valeur $\theta =
%      0,75$.
    \item Le seuil observé est le plus grand seuil de signification auquel on
      rejette $ \mathcal{H}_0$. Ainsi,
      \begin{equation*}
        p = 2 \prob{Z > 2,28} \approx 0,0226.
      \end{equation*}
      On rejette donc $ \mathcal{H}_0$ avec un niveau de confiance maximal de
      $97,74$~\%. %Cette valeur $p$ apparaît dans les résultats de la fonction \texttt{prop.test} en a) et b).
    \end{enumerate}
  
\end{solution}
\begin{solution}{6.9}
    \begin{enumerate}
    \item Il s'agit d'un test bilatéral sur une proportion avec un grand
      échantillon. La statistique du test est
      \begin{displaymath}
        Z = \frac{\hat{\theta} - 0,20}{%
          \sqrt{0,20 (1 - 0,20)/n}}
      \end{displaymath}
      et on rejette $ \mathcal{H}_0$ si $\abs{z} > z_{0,025} = 1,96$.
    \item En calculant la valeur de la statistique pour chacune des
      proportions données, on constate que toutes les statistiques
      sont plus inférieures à $1,96$. Auncun membre ne rejette donc
      l'hypothèse $ \mathcal{H}_0$.
    \item Étant donné que le seuil de signification est $5~\%$, si
      l'hypothèse $ \mathcal{H}_0$ est vraie, on peut s'attendre à un taux de
      rejet de $5$~\%.
    \item Si, en b), l'on n'a jamais rejeté l'hypothèse $ \mathcal{H}_0$, c'est
      que $100$~\% des intervalles de confiance à 95~\% pour $\theta$
      contiennent la valeur $0,20$.
    \item La valeur de la statistique est
      \begin{equation*}
        z = \frac{219/1124 - 0,20}{\sqrt{(0,20)(1 - 0,20)/1124}}
        = -0,4325
      \end{equation*}
      et $\abs{z} < 1,96$. Donc, on ne rejette pas $ \mathcal{H}_0$ à un seuil de
      signification de $5$~\%. La valeur $p$ associée est:
      \begin{align*}
        p &= \prob{\abs{Z} > -0,4325}\\
        &= 2 \prob{Z > 0,4325}\\
        &= 0,6654,
      \end{align*}
      ce qui représente le seuil de signification minimal auquel il
      est possible de rejeter $ \mathcal{H}_0$. %Ces résultats sont confirmés par
%      la fonction \texttt{prop.test} de \textsf{R}:
%<<echo=TRUE>>=
%prop.test(219, 1124, p = 0.2, correct = FALSE)
%@
    \end{enumerate}
  
\end{solution}
\begin{solution}{6.10}
    \begin{enumerate}
    \item Il s'agit d'un test sur la différence entre deux
      proportions. Il faut commencer par construire la statistique. On
      a
      \begin{align*}
        X &\sim \text{Binomiale}(n, \theta_1)\\
        Y &\sim \text{Binomiale}(m, \theta_2).
      \end{align*}
      Pour $n$ et $m$ grands, on a, approximativement,
      \begin{align*}
        X &\sim N(n\theta_1, n\theta_1(1 - \theta_1)) \\
        Y &\sim N(m\theta_2, m\theta_2(1 - \theta_2),
      \end{align*}
      et donc, toujours approximativement,
      \begin{align*}
        \hat{\theta}_1 &= \frac{X}{n}
        \sim N\left(\theta_1,
          \frac{\theta_1(1-\theta_1)}{n}\right) \\
        \hat{\theta}_2 &= \frac{Y}{m}
        \sim N\left(\theta_2, \frac{\theta_2(1-\theta_2)}{m}\right).
      \end{align*}
      Par conséquent,
      \begin{displaymath}
        \frac{(\hat{\theta}_1 - \hat{\theta}_2) - (\theta_1 -
          \theta_2)}{\sqrt{\theta_1(1-\theta_1)/n +
            \theta_2(1-\theta_2)/m}} \sim N(0, 1).
      \end{displaymath}
      Pour pouvoir calculer la valeur de cette statistique pour un
      échantillon aléatoire, on remplace $\theta_1$ et $\theta_2$ dans
      le radical par $\hat{\theta}_1 = X/n$ et $\hat{\theta}_2 = Y/m$,
      dans l'ordre. Un intervalle de confiance de niveau $1 - \alpha$
      pour $\theta_1 - \theta_2$ est donc
      \begin{displaymath}
        (\hat{\theta}_1 - \hat{\theta}_2) \pm
        z_{\alpha/2} \sqrt{\frac{\hat{\theta}_1 (1 - \hat{\theta}_1)}{n} +
          \frac{\hat{\theta}_2 (1 - \hat{\theta}_2)}{m}}.
      \end{displaymath}
      De manière similaire, la statistique utilisée pour tester la
      différence entre les deux proportions $\theta_1$ et $\theta_2$ est
      \begin{displaymath}
        Z =  \frac{(\hat{\theta}_1 - \hat{\theta}_2) - (\theta_1 -
          \theta_2)}{\sqrt{\hat{\theta}_1 (1 - \hat{\theta}_1)/n +
            \hat{\theta}_2 (1 - \hat{\theta}_2)/m}},
      \end{displaymath}
      et on rejette $ \mathcal{H}_0: \theta_1 = \theta_2$ en faveur de $ \mathcal{H}_1:
      \theta_1 \ne \theta_2$ si $\abs{z} > z_{\alpha/2}$.

      Ici, on a $x = 351$, $y = 41$, $n = 605$ et $m = 800 - 605 =
      195$. Ainsi, $\hat{\theta}_1 = 0,5802$, $\hat{\theta}_2 =
      0,2103$ et $\abs{z} = 10,44 > 1,96$. On rejette donc $ \mathcal{H}_0$ à un
     seuil de signification de $5$~\%. %La fonction \texttt{prop.test}
%      de \textsf{R} corrobore ces résultats:
%<<echo=TRUE>>=
%prop.test(c(351, 41), c(605, 195), correct = FALSE)
%@
    \item L'intervalle de confiance est
      \begin{displaymath}
        (\theta_1 - \theta_2) \in (0,3005, \, 0,4393).
      \end{displaymath}
      Comme $0$ n'appartient pas à cet intervalle, on rejette $ \mathcal{H}_0$.
    \item On cherche maintenant un intervalle de confiance pour la
      proportion de la population en faveur de l'introduction du taxe
      sur le tabac. On a une observation $x = 351 + 41 = 392$ d'une
      distribution Binomiale$(800, \theta)$, d'où $\hat{\theta} =
      392/800 = 0,49$. Un intervalle de confiance à 95~\% pour
      $\theta$ est
      \begin{align*}
        \theta &\in \hat{\theta} \pm 1,96 \sqrt{\frac{\hat{\theta} (1 -
            \hat{\theta})}{800}} \\
        &\in 0,49 \pm 1,96 \sqrt{\frac{0,49 (0,51)}{800}} \\
        &\in (0,4555, \, 0,5246).
      \end{align*}
      Vérification avec \textsf{R}:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{prop.test}\hlstd{(}\hlnum{351} \hlopt{+} \hlnum{41}\hlstd{,} \hlnum{800}\hlstd{,} \hlkwc{correct} \hlstd{=} \hlnum{FALSE}\hlstd{)}\hlopt{$}\hlstd{conf.int}
\end{alltt}
\begin{verbatim}
## [1] 0.4554900 0.5246056
## attr(,"conf.level")
## [1] 0.95
\end{verbatim}
\end{kframe}
\end{knitrout}
    \end{enumerate}
  
\end{solution}
\begin{solution}{6.11}
\begin{enumerate}
\item Premièrement, on ajuste le modèle Gamma aux données.
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hlstd{(MASS)}
\hlstd{m3} \hlkwb{<-} \hlkwd{fitdistr}\hlstd{(data,}\hlkwc{densfun}\hlstd{=}\hlstr{"gamma"}\hlstd{,}\hlkwc{start}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{shape}\hlstd{=}\hlnum{0.5}\hlstd{,}\hlkwc{rate}\hlstd{=}\hlnum{0.2}\hlstd{))}
\end{alltt}
\end{kframe}
\end{knitrout}
L'estimation du paramètre $\alpha$ et l'estimation de son écart-type sont
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{m3}\hlopt{$}\hlstd{estimate[}\hlnum{1}\hlstd{]}
\end{alltt}
\begin{verbatim}
##     shape
## 0.5199489
\end{verbatim}
\begin{alltt}
\hlstd{m3}\hlopt{$}\hlstd{sd[}\hlnum{1}\hlstd{]}
\end{alltt}
\begin{verbatim}
##      shape
## 0.02679359
\end{verbatim}
\end{kframe}
\end{knitrout}
Le quantile $97,5$\% de la loi normale standard est
$$
z_{0,025} = 1.96.
$$
On trouve l'intervalle de confiance bilatéral approximatif pour $\alpha$ comme suit:
\begin{multline*}
[\hat \alpha - z_{0,025} \hat \sigma_{\hat \alpha}, \hat \alpha + z_{0,025} \hat \sigma_{\hat \alpha}] = [0.51995 - 1.96 \times 0.02679, 0.51995 + 1.96 \times 0.02679]\\
= [0.46743, 0.57246].
\end{multline*}
L'intervalle ne contient pas la valeur $\alpha=1$. Il y a donc évidence, au seuil $5$\%, que $\alpha \ne 1$, c'est-à-dire que la distribution exponentielle n'est pas une bonne simplification du modèle Gamma.

\item Les hypothèses de test sont:
$$
\mathcal{H}_0  :  \alpha = 1, \mathcal{H}_1 :  \alpha \ne 1
$$
et la statistique de Wald est donnée par
$$
w_n = \frac{\hat \alpha - 1}{\hat \sigma_{\hat \alpha}}  = \frac{0.51995-1}{0.02679} = -17.91664.
$$
Clairement, $w_n$ est plus petite que
$$
- z_{0,025} = -1.96.
$$
Ainsi, $\mathcal{H}_0$ est rejetée à un niveau de confiance $5$\%. La conclusion est la même qu'en (a).

\item Pour calculer la statistique de test, on ajuste d'abord le modèle exponentiel aux données:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{m2} \hlkwb{<-} \hlkwd{fitdistr}\hlstd{(data,}\hlkwc{densfun}\hlstd{=}\hlstr{"exponential"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
La log-vraisemblance des deux modèles est donnée par
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{m3}\hlopt{$}\hlstd{loglik}
\end{alltt}
\begin{verbatim}
## [1] -865.6958
\end{verbatim}
\begin{alltt}
\hlstd{m2}\hlopt{$}\hlstd{loglik}
\end{alltt}
\begin{verbatim}
## [1] -963.2785
\end{verbatim}
\end{kframe}
\end{knitrout}
ce qui donne la statistique du rapport de vraisemblance
$$
w= 2\{\ell(\hat \alpha,\hat \beta)-\ell(\hat \beta)\} = 2 (-865.6958 + 963.2785) = 195.1653.
$$
Clairement, l'hypothèse que $\alpha=1$ est rejetée parce que la valeur de la statistique du rapport de vraisemblance est beaucoup plus grande que le quantile $97,5$\% de la distribution khi-carrée avec $1$ degré de liberté.
$$
\chi^2_{1,0.025} = 5.024.
$$
La conclusion est donc la même qu'en b): le modèle exponentiel n'est pas une simplification adéquare du modèle Gamma pour l'ajustement des données.
\end{enumerate}
\end{solution}
\begin{solution}{6.12}
\begin{enumerate}
\item L'hypothèse nulle est $\mathcal{H}_0 :$ les lignes et les colonnes sont indépendantes. On doit donc faire un test du $\chi^2$. On calcule les totaux des lignes:
\begin{align*}
r_1 &= 122+167+528+673 = 1490\\
r_2 &= 203+118+178+212 = 711
\end{align*}
 On calcule les totaux des colonnes:
\begin{align*}
c_1 &= 122+203 = 325\\
c_2 &= 167+118 = 285\\
c_3 &= 528+178 = 706\\
c_4 &= 673+212 = 885\\
\end{align*}
On a $n=2201$ et les nombre espérés dans les cellules sont calculés comme suit.
\begin{align*}
\widehat{\esp{n_{ij}}} &= r_ic_j/n\\
\widehat{\esp{n_{11}}} &= 1490*325/2201= 220.0136302.
\end{align*}
On trouve donc les compte espérés
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}
##        [,1]   [,2]   [,3]   [,4]
## [1,] 220.01 192.94 477.94 599.11
## [2,] 104.99  92.06 228.06 285.89
\end{verbatim}
\end{kframe}
\end{knitrout}
La statistique du $\chi^2$ est
\begin{align*}
X^2 =&\sum_{i=1}^2\sum_{j=1}^4 \frac{\{n_{ij}-\widehat{\esp{n_{ij}}}\}^2}{\widehat{\esp{n_{ij}}}}\\
& = \frac{(122-220.01)^2}{220.01}+\cdots+\frac{(212-285.89)^2}{285.89}\\
&= 190.39
\end{align*}
Le nombre de degrés de liberté est $1\times 3 = 3$ et la valeur critique donnée dans la table est $\chi^2_{3,95\%} = 7.81473$. Puisque $190.39>7.81473$, on rejette l'hypothèse nulle au seuil de 5~\%. La probabilité de survie dépend de la classe tarifaire.

\item On trouve
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{pchisq}\hlstd{(}\hlnum{190.39}\hlstd{,}\hlnum{3}\hlstd{,}\hlkwc{lower.tail}\hlstd{=}\hlnum{FALSE}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] 5.027618e-41
\end{verbatim}
\end{kframe}
\end{knitrout}

\item On peut tracer le diagramme en mosaïque avec les commandes suivantes. Le résultat se trouve dans la Figure~\ref{fig:test:Titanic}.
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{tableau} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlkwd{c}\hlstd{(}\hlnum{122}\hlstd{,}\hlnum{203}\hlstd{,}\hlnum{167}\hlstd{,}\hlnum{118}\hlstd{,}\hlnum{528}\hlstd{,}\hlnum{178}\hlstd{,}\hlnum{673}\hlstd{,}\hlnum{212}\hlstd{),}\hlkwc{nrow}\hlstd{=}\hlnum{2}\hlstd{,}
              \hlkwc{dimnames}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{Survived}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"No"}\hlstd{,}\hlstr{"Yes"}\hlstd{),}
                         \hlkwc{Class}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"1st"}\hlstd{,}\hlstr{"2nd"}\hlstd{,}\hlstr{"3rd"}\hlstd{,}\hlstr{"Crew"}\hlstd{)))}
\hlkwd{mosaicplot}\hlstd{(}\hlkwd{t}\hlstd{(tableau),} \hlkwc{color}\hlstd{=}\hlnum{TRUE}\hlstd{,} \hlkwc{main}\hlstd{=}\hlstr{""}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\begin{figure}
        \centering
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}
\includegraphics[width=0.6\textwidth]{figure/unnamed-chunk-48-1}

\end{knitrout}
        \caption{Diagramme en mosaïque des survivants du Titanic par classe tarifaire de
          l'exercice
          \ref{chap:tests}.\ref{ex:test:titanic}.}
        \label{fig:test:Titanic}
      \end{figure}

\end{enumerate}
\end{solution}
