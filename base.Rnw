\chapter{Modèles statistiques de base}
\label{chap:base}

\Opensolutionfile{reponses}[reponses-base]
\Opensolutionfile{solutions}[solutions-base]

\begin{Filesave}{reponses}
\bigskip
\section*{Réponses}

\end{Filesave}

\begin{Filesave}{solutions}
\section*{Chapitre \ref{chap:base}}
\addcontentsline{toc}{section}{Chapitre \protect\ref{chap:base}}

\end{Filesave}

<<echo=FALSE>>=
options(width = 55)
@


%%%
%%% Début des exercices
%%%

% La notion d'échantillon aléatoire

\begin{exercice} 
Est-ce que les énoncés suivants constituent des exemples d'échantillon aléatoire? Justifiez votre réponse.

\begin{enumerate}
\item Le nombre annuel de cas de cancer du sein causant un décès au Québec entre 1970 et 2018.
\item Le résultat de 20 lancers de dés non truqués lors d'une partie d'un jeu de société.
\end{enumerate}
\begin{rep}
a) non \, \, b) oui 
\end{rep}
\begin{sol}
\begin{enumerate}
\item Les progrès en médecine ont affecté grandement la probabilité de détection précoce du cancer du sein, donc la probabilité de survie. Il y a donc une tendance à la baisse, et ces données ne sont pas identiquement distribuées dans le temps.
\item Puisque chaque lancer est indépendant et identiquement distribué, les 20 lancers sont considérés comme un échantillon aléatoire de taille 20 de lancers de dé.
\end{enumerate}
\end{sol}
\end{exercice}

\begin{exercice}
Dans chacun des cas suivants, identifiez la loi de probabilité qui serait la plus appropriée selon le contexte de l'énoncé. Justifiez votre choix et spécifiez quels paramètres sont connus et lesquels sont inconnus.

\begin{enumerate}
\item La perte financière du propriétaire d'une maison rasée par les flammes.
\item Le nombre de sacs de grains de café devant être examinés avant de trouver 15 sacs contaminés.
\item Le nombre de sacs de grains de café contaminés parmi 15 sacs examinés.
\item La vitesse réelle d'un véhicule à un endroit spécifique sur l'autoroute.
\item La véritable résistance d'un câble utilisé dans un ordinateur.
\end{enumerate}
\begin{sol}
\begin{enumerate}
\item Il faudrait utiliser une distribution continue non négative sur l'intervalle $[0,\infty)$ étant donné que la perte financière est nécessairement positive et qu'il n'y a pas de borne supérieure naturelle. Des bons exemples de lois pourraient être : gamma, lognormale, Pareto.

\item La distribution adéquate est la loi binomiale négative. Considérant que chaque sac est indépendant des autres et a une probabilité $p$ d'être contaminé, la distribution est une loi binomiale négative avec paramètres $r=15$ et $p$ inconnu.

\item La loi binomiale est appropriée. Considérant que chaque sac est indépendant des autres et a une probabilité $p$ d'être contaminé, le nombre total de sacs contaminés suit une loi binomiale avec paramètres de taille $n=15$ et probabilité $p$ inconnu.

\item Le contexte est conforme à une distribution normale. La majorité des conducteurs vont tendre vers une vitesse moyenne malgré que certains vont conduire beaucoup plus vite ou lentement~; une distribution en forme de cloche semble donc appropriée. La moyenne $\mu$ et la variance $\sigma^2$ de la vitesse réelle des véhicules à cet endroit précis sur l'autoroute sont inconnues.

\item Le contexte suggère une loi Normale. Les câbles devraient avoir une résistance près de $\mu$, soit celle donnée par le producteur. L'écart-type $\sigma$ dépendra de la qualité de la précision de la fabrication, et est inconnu.
\end{enumerate}
\end{sol}
\end{exercice}

% Variables aléatoires discrètes et continues

\begin{exercice}
  La distribution de Weibull est fréquemment utilisée en assurance
  IARD pour la modélisation des montants de sinistres, entre autres.
  Sa fonction de répartition est
  \begin{displaymath}
    F(x) = 1 - e^{-\beta x^\alpha}, \quad x > 0, \alpha > 0, \beta > 0.
  \end{displaymath}
  \begin{enumerate}
  \item Déterminer la fonction de densité de probabilité de la
    Weibull.
  \item Calculer l'espérance et la variance de la Weibull.
  \end{enumerate}
  \begin{rep}
    \begin{inparaenum}
    \item $f(x) = \alpha \beta x^{\alpha - 1}e^{-\beta x^{\alpha}}$
    \item $\esp{X} = \beta^{-1/\alpha} \Gamma(1 + 1/\alpha)$, %
      $\var{X} = \beta^{-2/\alpha} (\Gamma(1 + 2/\alpha) -
      \Gamma(1 + 1/\alpha)^2)$
    \end{inparaenum}
  \end{rep}
  \begin{sol}
    \begin{enumerate}
    \item On a directement $f(x) = F^\prime(x) = \alpha \beta x^{\alpha
        - 1} e^{-\beta x^{\alpha}}$.
    \item On a
      \begin{align*}
        \esp{X}
        &= \int_0^\infty x f(x)\, dx \\
        &= \int_0^\infty \alpha \beta x^{\alpha} e^{-\beta x^{\alpha}}\,
        dx.
      \end{align*}
      On effectue le changement de variable $y = \beta x^{\alpha}$,
      d'où $dy = \alpha \beta x^{\alpha - 1}\, dx$ et donc
      \begin{align*}
        \esp{X}
        &= \frac{1}{\beta^{1/\alpha}}
        \int_0^\infty y^{1/\alpha} e^{-y} \,dy \\
        &= \frac{\Gamma(1 + \frac{1}{\alpha})}{\beta^{1/\alpha}}
        \int_0^\infty \frac{1}{\Gamma(1 + \frac{1}{\alpha})}\,
        y^{1/\alpha} e^{-y} \,dy \\
        &= \frac{\Gamma(1 + \frac{1}{\alpha})}{\beta^{1/\alpha}}
      \end{align*}
      puisque l'intégrande ci-dessus est la fonction de densité de
      probabilité d'une loi gamma de paramètre de forme $\alpha = 1 +
      \frac{1}{\alpha}$ et de paramètre d'échelle $\beta = 1$. En
      procédant exactement de la même façon, on trouve
      \begin{align*}
        \esp{X^2}
        &= \int_0^\infty x^2 f(x)\, dx \\
        &= \int_0^\infty \alpha \beta x^{\alpha + 1} e^{-\beta x^{\alpha}}\,
        dx \\
        &= \frac{1}{\beta^{2/\alpha}}
        \int_0^\infty y^{2/\alpha} e^{-y} \, dy \\
        &= \frac{\Gamma(1 + \frac{2}{\alpha})}{\beta^{2/\alpha}}.
      \end{align*}
      Par conséquent,
      \begin{equation*}
        \var{X} = \frac{\Gamma(1 + \frac{2}{\alpha}) -
          \Gamma(1 + \frac{1}{\alpha})^2}{\beta^{2/\alpha}}.
      \end{equation*}
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
Obtenir l'expression de $\Esp{X}$ et $\Var{X}$ quand la variable aléatoire $X$ suit une distribution Beta$(\alpha,\beta)$. [Indices:
\begin{itemize}
\item [i.] Pour tout $\alpha > 0$, $\Gamma(\alpha+1) = \alpha\Gamma(\alpha)$.

\item [ii.] Si $f$ est une densité, alors $\int_\mathbb{R}f(x)\d x=1$.]
\end{itemize}
\begin{rep}
$\ex(X)=\alpha/(\alpha+\beta)$ et $\Var{X}=(\alpha\beta)/\{(\alpha+\beta)^2(\alpha+\beta+1)\}$
\end{rep}
\begin{sol}
Soit $X$ une variable aléatoire avec distribution Beta$(\alpha,\beta)$. Alors,
\begin{align*}
\ex(X) & = \int_0^1 x \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1}\d x\\
&=\int_0^1  \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha}(1-x)^{\beta-1}\d x.
\end{align*}
Cette intégrale peut être résolue en reconnaissant la forme similaire à une distribution Beta$(\alpha+1,\beta)$ intégrée sur son domaine, mais avec les mauvaises constantes. On divise et multiplie par les constantes nécessaires pour trouver une intégrale avec valeur de 1.
\begin{align*}
\ex(X) & =\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)}\frac{\Gamma(\alpha+1)}{\Gamma(\alpha+1+\beta)} \int_0^1  \frac{\Gamma(\alpha+1+\beta)}{\Gamma(\alpha+1)\Gamma(\beta)}x^{\alpha}(1-x)^{\beta-1}\d x\\
&=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha+1+\beta)}\frac{\Gamma(\alpha+1)}{\Gamma(\alpha)}\\
&= \frac{\Gamma(\alpha+\beta)}{(\alpha+\beta)\Gamma(\alpha+\beta)}\frac{ \alpha \Gamma(\alpha) }{\Gamma(\alpha)}\\
&=\frac{\alpha}{\alpha+\beta}.
\end{align*}

De plus,
\begin{align*}
\ex\{X^2\} & = \int_0^1 x^2 \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1}\d x\\
&=\int_0^1  \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha+1}(1-x)^{\beta-1}\d x\\
& =\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)}\frac{\Gamma(\alpha+2)}{\Gamma(\alpha+2+\beta)} \int_0^1  \frac{\Gamma(\alpha+2+\beta)}{\Gamma(\alpha+2)\Gamma(\beta)}x^{\alpha}(1-x)^{\beta-1}\d x\\
&=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha+2+\beta)}\frac{\Gamma(\alpha+2)}{\Gamma(\alpha)}\\
&= \frac{\Gamma(\alpha+\beta)}{(\alpha+\beta+1)\Gamma(\alpha+\beta+1)}\frac{ (\alpha+1) \Gamma(\alpha+1) }{\Gamma(\alpha)}\\
&= \frac{\Gamma(\alpha+\beta)}{(\alpha+\beta+1)(\alpha+\beta)\Gamma(\alpha+\beta)}\frac{ (\alpha+1)\alpha \Gamma(\alpha) }{\Gamma(\alpha)}\\
&= \frac{(\alpha+1)\alpha}{(\alpha+\beta+1)(\alpha+\beta)}.
\end{align*}
La variance peut alors être calculée ainsi~:
\begin{align*}
\vr(X) &= \ex(X^2) - \{ \ex(X)\}^2 \\
&= \frac{(\alpha+1)\alpha}{(\alpha+\beta+1)(\alpha+\beta)}-\frac{\alpha^2}{(\alpha+\beta)^2} \\
&= \frac{\alpha}{\alpha+\beta}\left[\frac{\alpha+1}{\alpha+\beta+1}-\frac{\alpha}{\alpha+\beta}\right]\\
&= \frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}
\end{align*}

\end{sol}
\end{exercice}

\begin{exercice}
Calculer la fonction génératrice des moments $M$ d'une distribution de Poisson avec paramètre $\lambda>0$. Utilisez $M$ pour montrer que l'espérance et la variance d'une variable aléatoire Poisson sont égales.
\begin{rep}
$M_X(t) = \exp\{\lambda(e^t-1)\}$ pour tout $t \in \mathbb{R}$.
\end{rep}
\begin{sol}
Soit $X$ une variable aléatoire Poisson avec paramètre $\lambda>0$. Sa fonction génératrice des moments, pour tout $t \in \mathbb{R}$, est donnée par
\begin{align*}
M_X(t) = \ex (e^{tX}) = \sum_{k=0}^\infty e^{tk}\frac{\lambda^k e^{-\lambda}}{k!} =  e^{-\lambda}\sum_{k=0}^\infty \frac{\{\lambda e^t\}^k}{k!}.
\end{align*}
L'équation de droite est la série de Taylor de $\exp(\lambda e^t)$. Ainsi,
$$
M_X(t) = e^{-\lambda}e^{\lambda e^t} = \exp\{\lambda(e^t-1)\}.
$$
La $k$e dérivée de $M$ évaluée à $t=0$ donne le $k$e moment de $X$. Ainsi, 
$$
\ex(X) = M^\prime_X(0) = \left.\exp\{\lambda(e^t-1)\}\times \lambda e^t\right|_{t=0} = \lambda
$$
de façon similaire,
\begin{align*}
\ex(X^2) & = M^{\prime \prime}_X(0) = \left.\exp\{\lambda(e^t-1)\}\times \lambda^2 e^{2t}+\exp\{\lambda(e^t-1)\}\times \lambda e^{t}\right|_{t=0} = \lambda^2+\lambda
\end{align*}
Alors,
$$
\vr(X) = \ex(X^2) - \{\ex(X)\}^2 = \lambda^2+\lambda-\lambda^2=\lambda.
$$
\end{sol}
\end{exercice}

\begin{exercice}
Une station service opère deux pompes à essence. Chacune d'entre elles peut produire jusqu'à 10~000 litres d'essence par mois. La quantité totale d'essence pompée à la station chaque mois est une variable aléatoire $Y$, mesurée en 10~000 litres, avec fonction de densité de probabilité donnée par
$$
f(y)=\begin{cases}
y, & 0\leq y<1,\\
2-y, & 1\leq y <2,\\
0, &\mbox{ailleurs.}
\end{cases}
$$
\begin{enumerate}
\item Trouver la fonction de répartition $F$ de $Y$.
\item Calculer la probabilité que la station service pompe entre 8~500 et 11~500 litres d'essence dans un mois.
\item Quel est le revenu mensuel espéré si la station service vend son essence au prix de 2,10~\$ le litre~?
\end{enumerate}
 \begin{rep}
     b) 0.2775 \, \, c) 21~000
   \end{rep}
\begin{sol}
\begin{enumerate}
\item Le support de $Y$ est $[0,2]$, donc $F(y)=0$ pour $y<0$ et $F(y)=1$ pour $y>2$. Pour $0\leq y <1$,
$$
F(y)=\Pr[Y\leq y]=\int_0^y x\d x = \frac{y^2}{2}.
$$
Pour $1\leq y <2$,
$$
F(y)=\Pr[Y\leq y]=\int_0^1 x\d x +\int_1^y (2-x)\d x = 1-\frac{(2-y)^2}{2}.
$$
Ainsi la fonction de répartition de $Y$ est
$$
F(y)= \begin{cases}
0, & y<0\\
y^2/2, & 0\leq y<1\\
1- (2-y)^2/2, & 1\leq y <2\\
1, & y>2.
\end{cases}
$$

\item On souhaite trouver la probabilité que $10000 Y$ se situe entre 8~500 et 11~500:
\begin{align*}
\Pr[8500<10000Y\leq 11500] & = \Pr[0.85<Y\leq 1.15]\\
&=F(1.15)-F(0.85)\\
&=1- \frac{(2-1.15)^2}{2}-\frac{0.85^2}{2}=0.2775.
\end{align*}

\item On désire trouver l'espérance du revenu, qui est de 2,10~\$ par litre, donc $\ex[2.10\times 10000Y]=21000\ex[Y]$. On a
\begin{align*}
\ex[Y]&=\int_0^1 y^2\d y +\int_1^2 y(2-y)\d y\\
&=\left.\frac{y^3}{3}\right|_0^1+\left.y^2-\frac{y^3}{3}\right|_1^2\\
&=\frac{1}{3}+4-\frac{2^3}{3}-1+\frac{1}{3} = 1.
\end{align*}
Ainsi, l'espérance de revenu mensuel est de 21~000~\$.
\end{enumerate}
\end{sol}
\end{exercice}


% Moments d'une variable aléatoire
\begin{exercice}
  \label{ex:rappels:moyenne}
  Soit $X$ une variable aléatoire de moyenne $\mu$ et de variance
  $\sigma^2$. Déterminer la valeur de $c$ qui minimise $\esp{(X -
    c)^2}$.
  \begin{rep}
    $c = \mu$
  \end{rep}
  \begin{sol}
    On doit trouver le point où la fonction $f(c) = \esp{(X - c)^2}$
    atteint son minimum. Pour ce faire, il faut dériver par rapport à $c$. Or, $\frac{\text{d}}{\text{d}c} f(c) = -2 \esp{X - c} = 0$
    lorsque $\esp{X} - c = 0$, soit $c = \esp{X} = \mu$. De plus, il
    s'agit bien d'un minimum puisque $\frac{\text{d}^2}{\text{d}^2c} f(c)= 2 > 0$
    pour tout $c$.
  \end{sol}
\end{exercice}

\begin{exercice}
  Soit $M_X(t)$ la fonction génératrice des moments de la variable
  aléatoire $X$.
  \begin{enumerate}
  \item Soit $Y = aX + b$, où $a$ et $b$ sont des constantes
    quelconques. Démontrer que
    \begin{displaymath}
      M_Y(t) = e^{bt} M_{X}(at).
    \end{displaymath}
  \item Soient $X_1, \ldots, X_n$ des variables aléatoires indépendantes
    et $Y = X_1 + \dots + X_n$. Démontrer que
    \begin{displaymath}
      M_Y(t) = \prod_{j=1}^n M_{X_j}(t).
    \end{displaymath}
  \end{enumerate}
  \begin{sol}
    \begin{enumerate}
    \item On a
      \begin{align*}
        M_Y(t)
        &= \esp{e^{Yt}} \\
        &= \esp{e^{(aX + b)t}} \\
        &= \esp{e^{aXt} e^{bt}} \\
        &= e^{bt} \esp{e^{aXt}} \\
        &= e^{bt} M_X(at).
      \end{align*}
    \item On a
      \begin{align*}
        M_Y(t)
        &= \esp{e^{Yt}}\\
        &= \esp{e^{(X_1 + \dots + X_n) t}}\\
        &= \esp{e^{X_1 t} \cdots e^{X_n t}} \\
        \intertext{et, par indépendance entre les variables
          aléatoires,}
        M_Y(t)
        &= \esp{e^{X_1t}} \cdots \esp{e^{X_nt}} \\
        &= \prod_{i = j}^n M_{X_j}(t).
      \end{align*}
      Si, en plus, les variables aléatoires $X_1, \dots, X_n$ sont
      identiquement distribuées comme $X$, alors $M_Y(t) =
      (M_X(t))^n$.
    \end{enumerate}
  \end{sol}
\end{exercice}

% Loi des grands nombres
\begin{exercice} 
Soit $X_1,\ldots,X_n$ un échantillon aléatoire tiré d'une distribution avec densité
$$
f(x) = \left\{ \begin{array}{ll}
\frac{200}{x^3},& \quad x\geq 10\\
0, & \quad \mbox{ailleurs}\\
\end{array}\right.
$$
Est-ce qu'il est possible d'utiliser la Loi faible des grands nombres pour cet exemple? Justifiez.
\begin{rep}
Non.
\end{rep}
\begin{sol}
La Loi faible des grands nombres indique que, lorsque $n\to\infty$, $\bar X_n\stackrel{P}{\to}\ex[X]$, où $X_1,\ldots,X_n$ est une suite de variables aléatoires indépendantes et identiquement ditribuées. Cependant, le résultat tient seulement si $\ex[X^2] < \infty$, ce qui n'est pas le cas ici puisque
\begin{align*}
\ex[X^2]=\int_{10}^\infty \frac{200}{x^3}x^2 \d x =\int_{10}^\infty \frac{200}{x} \d x = \left. 200\ln(x)\right|_{10}^\infty = \infty.
\end{align*} 
Ainsi, il n'est pas possible d'appliquer la WLLN dans ce cas.
\end{sol}
\end{exercice}

\begin{exercice}
Soit $X_1,\ldots,X_n$ un échantillon aléatoire tiré d'une distribution avec densité
$$
f(x)=4(1-x)^3, \quad \mbox{ pour } 0\leq x\leq 1.
$$
Montrer que $\bar X_n$ converge en probabilité vers une contante et trouver cette constante.
\begin{rep}
1/5
\end{rep}
\begin{sol}
Si $X$ a la même distribution que $X_1, \ldots , X_n$ et $\vr(X)<\infty$, la loi faible des grands nombres implique que, quand $n \to \infty$,
$
\frac{1}{n} \, \sum_{i=1}^n X_i
$
converge en probabilité vers $\esp{X}$. Puisque $X$ suit une distribution Beta avec paramètres $\alpha=1$ et $\beta=4$,  $\esp{X}=\alpha/(\alpha+\beta)=1/5$ et 
$$
\var{X}=\frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}=\frac{4}{5^2\times 6}=\frac{2}{75}<\infty.
$$ 
Donc, la WLLN s'applique et $\bar X_n$ converge en probabilité vers 1/5.
\end{sol}
\end{exercice}

% Statistiques d'ordre

\begin{exercice}
  \label{ex:echantillon:min}%
  Soit $X_1, \dots, X_n$ un échantillon aléatoire tiré d'une loi avec
  fonction de répartition $F_X(\cdot)$ et $X_{(1)} \leq \dots \leq
  X_{(n)}$ les statistiques d'ordre correspondantes. Trouver la
  fonction de répartition de $X_{(1)} = \min (X_1, \dots X_n)$.
  \begin{rep}
    $F_{X_{(1)}}(x) = 1 - (1 -  F_X(x))^n$
  \end{rep}
  \begin{sol}
    Puisque $X_{(1)}$ est la plus petite valeur de l'échantillon, on a
    que
    \begin{align*}
      F_{X_{(1)}}(x)
      &= \prob{X_{(1)} \leq x} \\
      &= 1 - \prob{X_{(1)} > x} \\
      &= 1 - \prob{X_1 > x, X_2 > x, \dots, X_n > x}.
    \end{align*}
    Or, les variables aléatoires $X_1, \dots, X_n$ sont indépendantes
    et identiquement distribuées, d'où
    \begin{align*}
      F_{X_{(1)}}(x)
      &= 1 - \prob{X_1 > x} \prob{X_2 > x} \cdots \prob{X_n > x} \\
      &= 1 - (\prob{X > x})^n \\
      &= 1 - (1 -  F_X(x))^n.
    \end{align*}
  \end{sol}
\end{exercice}

\begin{exercice}
  Soient $X_{(1)} \leq X_{(2)} \leq X_{(3)} \leq X_{(4)}$ les
  statistiques d'ordre d'un échantillon aléatoire de taille $4$ issu
  d'une distribution avec fonction de densité de probabilité $f(x) =
  e^{-x}$, $0 < x < \infty$. Calculer $\prob{X_{(4)} > 3}$.
  \begin{rep}
    $1 - (1 - e^{-3})^4$
  \end{rep}
  \begin{sol}
    On cherche la probabilité que la plus grande valeur de
    l'échantillon soit supérieure à 3, soit le complément de la
    probabilité que toutes les valeurs de l'échantillon soient
    inférieures à 3:
    \begin{align*}
      \prob{X_{(4)} > 3}
      &= 1 - \prob{X_{(4)} \leq 3} \\
      &= 1 - \prob{X_1 \leq 3} \prob{X_2 \leq 3}
      \prob{X_3 \leq 3} \prob{X_4 \leq 3} \\
      &= 1 - (F_X(3))^4.
    \end{align*}
    Or, on aura reconnu en $f(x)$ la densité d'une loi exponentielle
    de paramètre $\lambda = 1$. Par conséquent, $F_X(x) = 1 - e^{-x}$
    et $\prob{X_{(4)} > 3} = 1 - (1 - e^{-3})^4$.
  \end{sol}
\end{exercice}

\begin{exercice}
  Soit $X_1, X_2, X_3$ un échantillon aléatoire issu d'une loi bêta de
  paramètres $\alpha = 2$ et $\beta = 1$. Calculer la probabilité que
  la plus petite valeur de l'échantillon soit supérieure à la médiane
  (théorique) de la distribution.
  \begin{rep}
    $1/8$
  \end{rep}
  \begin{sol}
    Soit $m$ la médiane de la distribution. On cherche $\prob{X_{(1)}
      > m}$. Avec le résultat de
    l'exercice~\ref{chap:base}.\ref{ex:echantillon:min},
    \begin{align*}
      \prob{X_{(1)} > m}
      &= 1 - \prob{X_{(1)} \leq m} \\
      &= 1 - F_{X_{(1)}}(m) \\
      &= 1 - (1 - (1 - F_X(m))^3)\\
      &= (1 - F_X(m))^3 \\
      &= \frac{1}{8},
    \end{align*}
    car $F_X(m) = 1 - F_X(m) = 1/2$ par définition de la médiane. Le
    type de distribution ne joue donc aucun rôle dans cet exercice.
  \end{sol}
\end{exercice}

\begin{exercice}
  Soit $X$ une variable aléatoire discrète avec fonction de masse de
  probabilité $\prob{X = x} = 1/6$, $x = 1, 2, 3, 4, 5, 6$. Démontrer
  que la fonction de masse de probabilité du minimum d'un échantillon
  aléatoire de taille $5$ issu de cette distribution est
  \begin{displaymath}
    \Prob{X_{(1)} = x} =
    \left(
      \frac{7 - x}{6}
    \right)^5 -
    \left(
      \frac{6 - x}{6}
    \right)^5, \quad x = 1, 2, 3, 4, 5, 6.
  \end{displaymath}
  \begin{sol}
    On a que $X$ est distribuée uniformément sur $\{1, \dots, 6\}$,
    d'où $F_X(x) = x/6$, $x = 1, \dots, 6$. De
    l'exercice~\ref{chap:base}.\ref{ex:echantillon:min}, on a
    que
    \begin{align*}
      F_{X_{(1)}}(x)
      &= 1 - (1 - F_X(x))^5 \\
      &= 1 - \left( 1 - \frac{x}{6} \right)^5.
    \end{align*}
    Par conséquent, la fonction de masse de probabilité du minimum est
    \begin{align*}
      \prob{X_{(1)} = x}
      &= \lim_{y \rightarrow x^+} F_{X_{(1)}}(y) -
      \lim_{y \rightarrow x^-} F_{X_{(1)}}(y) \\
      &= F_{X_{(1)}}(x) - F_{X_{(1)}}(x - 1) \\
      &= \left(1 - \frac{x-1}{6} \right)^5 -
      \bigg( 1 - \frac{x}{6} \bigg)^5 \\
      &= \left(\frac{7 - x}{6}\right)^5 -
      \left(\frac{6 - x}{6}\right)^5.
    \end{align*}
  \end{sol}
\end{exercice}

\begin{exercice}
  Soient $X_{(1)} \leq \dots \leq X_{(n)}$ les statistiques d'ordre
  d'un échantillon aléatoire tiré d'une loi de Weibull, dont la
  fonction de répartition est $F_X(x) = 1 - e^{-\beta x^\alpha}$.
  Calculer la fonction de répartition, la fonction de densité et
  l'espérance de $X_{(1)}$.
  \begin{rep}
    $X_{(1)} \sim \text{Weibull}(\alpha, n\beta)$.
  \end{rep}
  \begin{sol}
    De l'exercice~\ref{chap:base}.\ref{ex:echantillon:min}, on
    a
    \begin{align*}
      F_{X_{(1)}}(x)
      &= 1 - (1 - F_X(x))^n \\
      &= 1 - (e^{-\beta x^\alpha})^n \\
      &= 1 - e^{-n \beta x^\alpha},
    \end{align*}
    d'où $X_{(1)} \sim \text{Weibull}(\alpha, n \beta)$. Ainsi, la fonction de densité de probabilité du minimum de
    l'échantillon est
    \begin{equation*}
      f_{X_{(1)}}(x) = n \beta \alpha x^{\alpha - 1} e^{-n \beta x^\alpha}
    \end{equation*}
    et l'espérance est
    \begin{equation*}
      \esp{X_{(1)}} = \frac{\Gamma(1 + 1/\alpha)}{(n \beta)^{\frac{1}{\alpha}}}.
    \end{equation*}
  \end{sol}
\end{exercice}

\begin{exercice}
\label{ex:conjointe}
Soit un échantillon aléatoire $X_1,\ldots,X_n$ tiré d'une distribution $F$ avec densité $f(x)$, pour $x\in\mathbb{R}$. Trouver la fonction de densité conjointe de $X_{(1)}=\min (X_1, \dots X_n)$ et de $X_{(n)}= \max (X_1, \dots X_n)$, $f_{X_{(1)}, X_{(n)}}(x,y)$.
\begin{rep}
$f_{X_{(1)}, X_{(n)}}(x,y) = n (n - 1) (F(y) - F(x))^{n - 2}  f(x) f(y), \quad x<y$
\end{rep}
\begin{sol}
À partir de la fonction de répartition, on a
\begin{align*}
F_{X_{(1)}, X_{(n)}}(x,y)&= \prob{X_{(1)} \leq x, X_{(n)} \leq y} \\
&= \prob{X_{(n)} \leq y} - \prob{X_{(1)} > x, X_{(n)} \leq y} \\
&= \prob{X_1 \leq y, \dots, X_n \leq y} - \prob{x < X_1 \leq y, \dots, x < X_n \leq y} \\
&= (F(y))^n - (F(y)-F(x))^n, \quad \text{car iid.}
\end{align*}
Donc, pour $x < y$,
$$
f_{X_{(1)}, X_{(n)}}(x,y) = \frac{\d F_{X_{(1)}, X_{(n)}}(x,y)}{\d x \d y} = n (n - 1) (F(y) - F(x))^{n - 2}  f(x) f(y).
$$
\end{sol}
\end{exercice}

\begin{exercice}
\label{ex:etendue}
Soit un échantillon aléatoire $X_1,\ldots,X_n$. L'\emph{étendue} (ou \emph{dispersion}) empirique est
\begin{displaymath}
   R = X_{(n)} - X_{(1)},
\end{displaymath}
et la \emph{mi-étendue} (ou \emph{mi-dispersion}) empirique est
\begin{displaymath}
   T = \frac{X_{(1)} + X_{(n)}}{2}.
\end{displaymath}
En utilisant le fait que la densité conjointe de $X_{(1)}$ et de $X_{(n)}$ est donnée, pour $x<y$, par
\begin{displaymath}
  f_{X_{(1)}, X_{(n)}}(x,y) = n (n - 1) (F_X(y) - F_X(x))^{n - 2}  f_X(x) f_X(y),
\end{displaymath}
trouver la distribution conjointe de $(R,T)$.
\begin{rep}
$f_{R, T}(r, t) = n (n - 1)\{ F_X(t + r/2) - F_X(t - r/2)\}^{n - 2}
    f_X(t + r/2) f_X(t - r/2),$ 
    
pour $r > 0$ et $-\infty < t < \infty$.
\end{rep}
\begin{sol}
On pose 
$$
r = y - x \mbox{  et } t= \frac{x + y}{2}
$$
ce qui est équivalent à
$$
    x = -\frac{r}{2} + t \mbox{  et }
    y = \frac{r}{2} + t.
$$
Le jacobien de la transformation de $(x, y)$ vers $(r, t)$ est
\begin{equation*}
  J =  \begin{vmatrix}
    -1/2 & 1 \\
    1/2  & 1
  \end{vmatrix}
  = -1.
\end{equation*}
On a donc que la densité conjointe de l'étendue $R$ et de la mi-étendue $T$ est
 \begin{displaymath}
    f_{R, T}(r, t) = n (n - 1)
    \left(
      F_X\left(t + \frac{r}{2}\right) -
      F_X\left(t - \frac{r}{2}\right)
    \right)^{n - 2}
    f_X\left(t + \frac{r}{2}\right)
    f_X\left(t - \frac{r}{2}\right),
  \end{displaymath}
  pour $r > 0$ et $-\infty < t < \infty$.
%
%  La densité de l'étendue est
%  \begin{displaymath}
%    f_R(r) = \int_{-\infty}^\infty f_{R, T}(r, t)\, dt
%  \end{displaymath}
%  alors que celle de la mi-étendue est
%  \begin{displaymath}
%    f_T(t) = \int_{0}^\infty f_{R, T}(r, t)\, dr.
%  \end{displaymath}
\end{sol}
\end{exercice}

\begin{exercice}
\label{ex:etendueunif}
Si $X \sim \mathcal{U}(0, 1)$, montrer que la densité de l'étendue est
$ f_R(r) = n (n - 1) r^{n - 2} (1 - r),$ 
pour $0 < r < 1$.

\begin{sol}
Ici, $f_X(x)=1$ pour $x\in(0,1)$ et $F_X(x)=x$, pour $x\in(0,1)$. Selon l'exercice \ref{chap:base}.\ref{ex:etendue}, on trouve que
\begin{align*}
f_{R, T}(r, t) &= n (n - 1)\{ F_X(t + r/2) - F_X(t - r/2)\}^{n - 2}
    f_X(t + r/2) f_X(t - r/2)\\
&= n (n - 1)\{ (t + r/2) - (t - r/2)\}^{n - 2}\\
&= n (n - 1) r^{n-2},
\end{align*}
pour $0 < r < 1$ et $t + r/2 \in(0,1)$ et $t - r/2\in(0,1)$, donc $\frac{r}{2} < t < 1 - \frac{r}{2}$. 
Par conséquent,
\begin{align*}
  f_R(r) &= n (n - 1) r^{n - 2} \int_{r/2}^{1 - r/2} dt \\
   &= n (n - 1) r^{n - 2} (1 - r), \quad 0 < r < 1.
  \end{align*}
%
%  De manière similaire, on peut démontrer que
%  \begin{equation*}
%    f_T(t) =
%    \begin{cases}
%      n (2t)^{n - 1},        & 0 < t < 1/2 \\
%      n [2 (1 - t)]^{n - 1}, & 1/2 < t < 1.
%    \end{cases}
%  \end{equation*}
\end{sol}
\end{exercice}

\begin{exercice}
  Calculer la probabilité que l'étendue d'un échantillon aléatoire
  de taille $4$ issu d'une loi uniforme sur l'intervalle $(0, 1)$ soit
  inférieure à $1/2$.
  \begin{rep}
    $5/16$
  \end{rep}
  \begin{sol}
    Soit $R$ l'étendue de l'échantillon aléatoire. Avec l'exercice \ref{chap:base}.\ref{ex:etendueunif}, on sait que
    \begin{displaymath}
      f_R(x) = n (n - 1) x^{n - 2} (1 - x), \mbox{ pour } x\in(0,1).
    \end{displaymath}
    Par conséquent
    \begin{align*}
      \Prob{R \leq \frac{1}{2}}
      &= \int_{0}^{1/2} f_X(x)\, dx\\
      &= (4)(3)\int_{0}^{1/2} x^2 (1 - x)\, dx\\
      &= \frac{5}{16}.
    \end{align*}
  \end{sol}
\end{exercice}

\begin{exercice}
  Si un échantillon de taille $2$ est tiré d'une loi bêta avec
  paramètres $\alpha = 1$ et $\beta = 2$, quelle est la probabilité
  que l'une des deux valeurs de l'échantillon soit au moins deux fois
  plus grande que l'autre? (\emph{Astuce}: intégrer la densité
  conjointe des deux valeurs de l'échantillon au-dessus de la surface
  correspondant à la probabilité recherchée.)
  \begin{rep}
    $7/12$
  \end{rep}
  \begin{sol}
    On a que $X \sim \text{Bêta}(1, 2)$, c'est-à-dire que $f_X(x) =
    2(1 - x)$, $0 < x < 1$. Soit $X_1, X_2$ un échantillon aléatoire
    tiré de cette densité. Par indépendance, on a
    \begin{align*}
      f_{X_1 X_2}(x_1, x_2)
      &= f_{X_1}(x) f_{X_2}(x) \\
      &= 4 (1 - x_1)(1 - x_2).
    \end{align*}
    On cherche $\prob{X_2 \geq 2X_1 \cup X_1 \geq 2X_2}$. Par
    définition,
    \begin{equation*}
      \prob{X_1 \geq 2X_2 \cup X_2 \geq 2X_1}
      = \iint\limits_{\mathcal{R}} f_{X_1 X_2}(x_1, x_2) \, dx_2\, dx_1,
    \end{equation*}
    où $\mathcal{R}$ est la région du domaine de définition de
    $f_{X_1X_2}$ telle que $x_1 > 2x_2$ ou $x_2 > 2x_1$. Cette région
    est représentée à la figure~\ref{fig:echantillon:domaine}. On a
    donc
    \begin{align*}
      \prob{X_1 \geq 2X_2 \cup X_2 \geq 2X_1}
      &= 4 \int_0^{1/2} \int_{2x_1}^1 (1 - x_1)(1 - x_2)\, dx_2\,dx_1 \\
      &\phantom{=}
      + 4 \int_0^{1/2} \int_{2x_2}^1 (1 - x_1)(1 - x_2)\, dx_1\,dx_2 \\
      &= 4 \int_0^{1/2} (1 - x_1)
      \left(
        \frac{1}{2} - 2x_1 + 2x_1^2
      \right)\, dx_1 \\
      &\phantom{=}
      + 4 \int_0^{1/2} (1 - x_2)
      \left(
        \frac{1}{2} - 2x_2 + 2x_2^2
      \right)\, dx_2 \\
      &= \frac{7}{12}.
    \end{align*}
    \begin{figure}
      \centering
<<echo=FALSE, fig=TRUE, out.width = "0.6\\textwidth">>=
plot(0:1, 0:1, pch = NA, xlab = expression(x[1]), ylab = expression(x[2]))
rect(0, 0, 1, 1, lwd = 2)
polygon(c(0, 0, 0.5), c(0, 1, 1), density = 10, angle = 135)
polygon(c(0, 1, 1), c(0, 0, 0.5), density = 10, angle = 135)
@
      \caption{Domaine de définition de $f_{X_1X_2}(x_1, x_2) =  4 (1
        - x_1)(1 - x_2)$, $x_1, x_2 \in (0, 1)$. Les zones hachurées
        représentent les aires où $x_2 > 2x_1$ ou $x_1 > 2x_2$.}
      \label{fig:echantillon:domaine}
      \end{figure}
  \end{sol}
\end{exercice}

\begin{exercice}
  Soit $X \sim \mathcal{U}(0, 1)$. Calculer l'espérance de la mi-étendue $T = (X_{(1)} + X_{(n)})/2$ d'un
  échantillon de taille $n$ issu de cette distribution.
  \begin{rep}
    $1/2$.
  \end{rep}
  \begin{sol}
    Soit $T = (X_{(1)} + X_{(n)})/2$ la mi-étendue et $R$ l'étendue.
    On sait que, pour $r > 0$ et $-\infty < t < \infty$, 
    \begin{displaymath}
      f_{RT}(r, t) = n(n-1)r^{n - 2}.
    \end{displaymath}
    On doit calculer la densité marginale de $T$. Il faut voir que le
    domaine de $R$ (et donc le domaine d'intégration) dépend
    indirectement de $T$. En effet, si $0 \leq t \leq 1/2$, on doit
    avoir $0 < r < 2t$. Par contre, si $1/2 < t < 1$, il faut que $0 <
    r < 2(1-t)$. On obtient
    \begin{align*}
      f_T(t) &=
      \begin{cases}
        n(2t)^{n-1}, & 0 < t < 1/2 \\
        n(2(1 - t))^{n - 1}, & 1/2 < t < 1.
      \end{cases}
    \end{align*}
    Ainsi,
    \begin{align*}
      \esp{T} &= 2^{n - 1} n
      \left(
        \int_0^{1/2}t^n\,dt +
        \int_{1/2}^1 t (1 - t)^{n - 1}\, dt
      \right) \\
      &= 2^{n-1}n
      \left(
        \frac{0,5^{n+1}}{n+1} +
        \frac{n+2}{n(n + 1)}
        \left(
          \frac{1}{2^{n+1}}
        \right)
      \right) \\
      &= \frac{1}{2}.
    \end{align*}
  \end{sol}
\end{exercice}

\begin{exercice}
  Soit $X_1, \dots, X_n$ un échantillon aléatoire d'une loi uniforme
  sur l'intervalle $(0, 1)$.
   \begin{enumerate}
   \item Calculer la moyenne et la variance de $R = X_{(n)} - X_{(1)}$.
   \item Calculer la moyenne et la variance de $T = (X_{(1)} + X_{(n)})/2$.
   \end{enumerate}
   \begin{rep}
     \begin{enumerate}
     \item $\esp{R} = (n - 1)/(n + 1)$ et $\var{R} = (2n - 2)/[(n +
       1)^2 (n + 2)]$.
     \item $\esp{T} = 1/2$ et $\var{T} = 1/[2 (n + 1)(n + 2)]$.
     \end{enumerate}
   \end{rep}
   \begin{sol}
   On sait que $X_i \sim U(0, 1)$. On trouve la fonction de répartition du minimum $X_{(1)}$ avec
$$
   F_{X_{(1)}}(x)= 1 - (1 - F_X(x))^n = 1 - (1-x)^n ,
$$
   d'où sa fonction de densité est
$$
   f_{X_{(1)}}(x)=\frac{\d}{\d x} F_{X_{(1)}}(x) = n(1-x)^{n-1}
$$
 qui peut se réécrire sous la forme
 $$
 f_{X_{(1)}}(x)=\frac{\Gamma(1+n)}{\Gamma(1)\Gamma(n)}x^{1-1}(1-x)^{n-1}.
 $$
 On remarque que $X_{(1)} \sim \text{Bêta}(1, n)$. De la même façon pour $X_{(n)}$,
$$
   F_{X_{(n)}}(x)= (F_X(x))^n =x^n \text{ et }f_{X_{(n)}}(x)=\frac{\d}{\d x} F_{X_{(n)}}(x) = n x^{n-1}
$$
 qui peut se réécrire sous la forme
 $$
 f_{X_{(n)}}(x)=\frac{\Gamma(n+1)}{\Gamma(n)\Gamma(1)}x^{n-1}(1-x)^{1-1}.
 $$
 On remarque que $X_{(n)} \sim \text{Bêta}(n, 1)$. Ainsi, depuis l'exercice~\ref{chap:base}.\ref{ex:conjointe}, la densité conjointe de $(X_{(1)},X_{(n)})$ peut être exprimée comme suit, pour $0<x<y<1$,
$$
f_{X_{(1)},X_{(n)}}(x, y) = n(n - 1)(y - x)^{n-2}.
$$
Ainsi,
     \begin{equation*}
       \Esp{X_{(1)}X_{(n)}} = n (n - 1) \int_0^1 x \int_x^1
       y(y - x)^{n-2}\,dy\,dx.
     \end{equation*}
     L'intégrale intérieure ci-dessus se résoud par parties en posant
     $u = y$ et $dv = (y - x)^{n - 2}\,dy$. On obtient alors
     \begin{align*}
       \Esp{X_{(1)}X_{(n)}} &= n(n - 1) \int_0^1 x
       \left(
         \frac{(y-x)^{n-1}y}{n - 1} -
         \frac{1}{n - 1} \int_x^1 (y - x)^{n - 1}\, dy
       \right)\, dx\\
       &= n \int_0^1 x (1 - x)^{n-1}\, dx -
       \int_0^1 x (1 - x)^n \,dx \\
       &= \frac{1}{n+1} - \frac{1}{(n+1)(n+2)}\\
       &= \frac{1}{n+2},
     \end{align*}
     en intégrant une seconde fois par parties. Par conséquent,
     \begin{align*}
       \Cov{X_{(1)}, X_{(n)}} &= \Esp{X_{(1)} X_{(n)}} -
       \Esp{X_{(1)}}\Esp{X_{(n)}} \\
       &= \frac{1}{n + 2} -
       \left(
         \frac{1}{n + 1}
       \right)
       \left(
         \frac{n}{n + 1}
       \right) \\
       &= \frac{1}{(n + 1)^2 (n + 2)}.
     \end{align*}
     \begin{enumerate}
       \item On a
         \begin{align*}
           \Esp{R} &= \Esp{X_{(n)}} - \Esp{X_{(1)}}\\
           &= \frac{n}{n+1} - \frac{1}{n+1}\\
           &= \frac{n-1}{n+1}
         \end{align*}
         et
         \begin{align*}
           \Var{R} &= \Var{X_{(1)}} + \Var{X_{(n)}} -
           2\, \Cov{X_{(1)}, X_{(n)}}\\
           &= \frac{n}{(n+1)^2(n+2)} + \frac{n}{(n+1)^2(n+2)} -
           \frac{2}{(n+1)^2(n+2)} \\
           &=\frac{2n-2}{(n+1)^2(n+2)}.
         \end{align*}
       \item On a
         \begin{align*}
           \Esp{T} &= \frac{\Esp{X_{(1)}} + \Esp{X_{(n)}}}{2}\\
           &= \frac{1}{2}\left(\frac{n}{n+1} + \frac{1}{n+1}\right)\\
           &= \frac{1}{2}
         \end{align*}
         et
         \begin{align*}
           \Var{T} &= \frac{\Var{X_{(1)}}+\Var{X_{(n)}} +
             2\,\Cov{X_{(1)}, X_{(n)}}}{4}\\
           &= \frac{1}{4}
           \left[
             \frac{n}{(n+1)^2(n+2)} +
             \frac{n}{(n+1)^2(n+2)} +
             \frac{2}{(n+1)^2(n+2)}
           \right] \\
           &= \frac{1}{2(n+1)(n+2)}.
         \end{align*}
       \end{enumerate}
   \end{sol}
 \end{exercice}



\Closesolutionfile{solutions}
\Closesolutionfile{reponses}


%\section*{Exercices proposés dans \cite{Wackerly:mathstat:7e:2008}}
%
%\begin{trivlist}
%\item 3.145--3.151, 3.153, 3.155, 3.158, 3.159, 3.161, 3.162, 3.163
%\end{trivlist}


%%%
%%% Insérer les réponses
%%%
\input{reponses-base}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "exercices_analyse_statistique"
%%% coding: utf-8-unix
%%% End:
